#pragma kernel ClearMassBuffers
#pragma kernel ClearGridBuffers
#pragma kernel BoundaryAndInterval
#pragma kernel GatherAndWrite

#include "Assets/ParallelReductionSum/MpmStruct.hlsl"

//#define THREAD_1D 256
#define THREAD_1D 4
#define FLOAT_TO_INT_DIGIT 1024

uint _NumOfParticles;


RWStructuredBuffer<uint2> _GridAndMassIdsBuffer;
//RWStructuredBuffer<P2GMass> _P2GMassBuffer;
RWStructuredBuffer<uint> _P2GMassBuffer;
StructuredBuffer<uint2> _GridIndicesBuffer;

//Output 1
RWStructuredBuffer<uint2> _BoundaryAndIntervalBuffer;

//Output 2
//RWStructuredBuffer<LockMpmCell> _GridBuffer;
RWStructuredBuffer<LockMpmCell> _GridBuffer;

//RWStructuredBuffer<P2GMass> _OutputP2gMassBuffer;
RWStructuredBuffer<uint> _OutputP2gMassBuffer;

[numthreads(THREAD_1D,1,1)]
void ClearMassBuffers(uint3 DTid : SV_DispatchThreadID)
{
	uint laneId = DTid.x;
	//_GridAndMassIdsBuffer[laneId] = uint2(0xFFFFFFFF, 0xFFFFFFFF);
	//_GridPingPongBuffer[laneId] = uint2(0xFFFFFFFF, 0xFFFFFFFF);
	//_GridAndMassIdsBuffer[laneId] = uint2(0, 0);
	//_GridPingPongBuffer[laneId] = uint2(0, 0);
	//P2GMass p2gMass;
	//p2gMass.mass = 0;
	//p2gMass.mass_x_velocity = 0;
	//_P2GMassBuffer[laneId] = p2gMass;
	_BoundaryAndIntervalBuffer[laneId] = uint2(0,0);
	_OutputP2gMassBuffer[laneId] = 0;
}

[numthreads(THREAD_1D,1,1)]
void ClearGridBuffers(uint3 DTid : SV_DispatchThreadID)
{
	uint cellId = DTid.x;
	//_GridMassBuffer[cellId] = 0;
	//_GridMassVelBuffer[cellId] = int3(0,0,0);

	LockMpmCell cell;
	cell.mass = 0;
	cell.mass2 = 0;
	cell.mass_x_velocity = int3(0,0,0);
	cell.mass_x_velocity2 = int3(0,0,0);
	cell.velocity = float3(0,0,0);
	cell.force = float3(0,0,0);
	cell.padding = float2(0,0);
	_GridBuffer[cellId] = cell;
}

//
// Ming Gao, Xinlei Wang, Kui Wu, ..,
// GPU Optimization of Material Point Methods,
// ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH Asia), 2018
// https://dl.acm.org/doi/10.1145/3272127.3275044
// http://pages.cs.wisc.edu/~sifakis/papers/GPU_MPM.pdf
//
[numthreads(THREAD_1D,1,1)]
void BoundaryAndInterval(
    // Unique id of entire thread
    // numthreads.x * groups.x	
	uint3 DTid : SV_DispatchThreadID,

    // Group ID
    // example:
    //   if numthreads is (4,1,1)
    //   0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3
    uint3 groupId : SV_GroupID,

    // Group index which is converted groupThreadId(3D) to 1D's number.
    // example:
    //   if numthreads is (4,1,1)
    //   0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3
	uint GI : SV_GroupIndex

) {
	const uint laneId = DTid.x;
	if (laneId-1 < 0) { return; }
	const uint cellId = _GridAndMassIdsBuffer[laneId].x;
	const uint prevCellId = _GridAndMassIdsBuffer[laneId-1].x;

	// 
	// Mark a boundary between different cells
	//
	// laneId == 0 does not have previous cell id. That's why
	// cellId != prevCellId: if cell ids are different, it is boundary point
	// GI == 0: boundary of group shared
	//
	uint boundary = (laneId == 0 || cellId != prevCellId
		|| GI == 0) ? 1 : 0;

	uint laneIdEnd = _GridIndicesBuffer[cellId].y;

	//
	// Mark region interval
	//
	// If the end of lane index is less than group shared boundary point,
	// the end is _GridIndicesBuffer[cellId].y.
	// else, the end is group shared boundary point
	//
	laneIdEnd = (laneIdEnd < (groupId.x + 1) * THREAD_1D)
		? laneIdEnd
		: (groupId.x + 1) * THREAD_1D;
	uint regionInterval = laneIdEnd - 1 - laneId;

	_BoundaryAndIntervalBuffer[laneId] = uint2(boundary, regionInterval);
}


//groupshared float blockMass[512];
//groupshared float3 blockMassXVelocity[512];
//groupshared int blockMass[512];
groupshared int blockMass[THREAD_1D * 2];

//void GatherAndWrite(
//	uint3 Gid  : SV_GroupID,
//	uint3 DTid : SV_DispatchThreadID,
//	uint3 GTid : SV_GroupThreadID,
//	uint  GI : SV_GroupIndex)
//{
[numthreads(THREAD_1D,1,1)]
void GatherAndWrite(uint3 DTid : SV_DispatchThreadID, uint GI : SV_GroupIndex)
{
	const uint laneId = DTid.x;
	uint2 cellAndMassId = _GridAndMassIdsBuffer[laneId];
	uint cellIndex  = cellAndMassId.x;
	uint massIndex  = cellAndMassId.y;
	uint2 startAndEndIndices = _GridIndicesBuffer[cellIndex];
	uint startLaneId = startAndEndIndices.x;
	uint endLaneId = startAndEndIndices.y;

	uint2 boundaryAndInterval = _BoundaryAndIntervalBuffer[laneId];
	uint boundary = boundaryAndInterval.x;
	uint regionInterval = boundaryAndInterval.y;
	uint particleId = _GridAndMassIdsBuffer[startLaneId].y;

	// Store each particle info of 256 threads
	//P2GMass p2gMass = _P2GMassBuffer[massIndex];
	//blockMass[GI] = p2gMass.mass;
	//blockMassXVelocity[GI] = p2gMass.mass_x_velocity; //仮
	blockMass[GI] = _P2GMassBuffer[massIndex];
	GroupMemoryBarrierWithGroupSync();

    //
    // TODO(Tasuku): ここのforの回数を変動的にできるようにする
    //
	//for(uint stride = 1; stride < 256; stride <<= 1)
	for(uint stride = 1; stride < THREAD_1D; stride <<= 1)
	{
		if (stride <= regionInterval) {
			// stride <= interval
			// only sum within the group(same grid index)

			blockMass[GI] += blockMass[GI+stride];
			//blockMassXVelocity[GI] += blockMassXVelocity[GI+stride];
		}
		GroupMemoryBarrierWithGroupSync();
	}

	// Only the boundary node (Leader node) needs to write
	if (boundaryAndInterval.x)
	{
        _OutputP2gMassBuffer[laneId] = blockMass[GI];

		//Save into a cell
		int intMass = (int) (blockMass[GI] * FLOAT_TO_INT_DIGIT);
		//InterlockedAdd(_GridMassBuffer[cellIndex], intMass);
		//InterlockedAdd(_GridMassVelBuffer[cellIndex].x, intMass);

		InterlockedAdd(_GridBuffer[cellIndex].mass, intMass);
		InterlockedAdd(_GridBuffer[cellIndex].mass_x_velocity.x, intMass);
		InterlockedAdd(_GridBuffer[cellIndex].mass_x_velocity.y, intMass);
		InterlockedAdd(_GridBuffer[cellIndex].mass_x_velocity.z, intMass);
	 	//InterlockedAdd(_GridBuffer[cellIndex].mass_x_velocity, int3(intMass, intMass, intMass));
	}
}